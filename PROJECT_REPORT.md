# Smartphone Review Sentiment Analysis â€” Complete Research Documentation

**Research Paper | Minor Project 2**  
**Date:** February 2026  
**Focus:** Multi-device sentiment analysis of Indian e-commerce smartphone reviews using NLP, data augmentation, and ML-based scoring for purchase prediction

---

## Table of Contents

1. [Project Overview & Motivation](#1-project-overview--motivation)
2. [System Architecture & SDLC Model](#2-system-architecture--sdlc-model)
3. [Use Case Diagram](#3-use-case-diagram)
4. [Phase 1 â€” Data Collection (Scraping)](#4-phase-1--data-collection-scraping)
   - [iPhone 15 & 16 â€” Flipkart (Page-based)](#41-iphone-15--16--flipkart-page-based)
   - [iQOO Z10 â€” Flipkart (Page-based)](#42-iqoo-z10--flipkart-page-based)
   - [iPhone 14 â€” Amazon (Failed)](#43-iphone-14--amazon-scraper-failed)
   - [iPhone 14 â€” Flipkart (Failed + Reason)](#44-iphone-14--flipkart-scraper-failures)
   - [Technology Stack & Why Each Was Chosen](#45-technology-stack--rationale)
5. [Phase 2 â€” Word Cloud Generation](#5-phase-2--word-cloud-generation)
6. [Phase 3 â€” Data Augmentation](#6-phase-3--data-augmentation)
7. [Phase 4 â€” Feature Engineering & Selection](#7-phase-4--feature-engineering--selection)
8. [Phase 5 â€” Sentiment Analysis](#8-phase-5--sentiment-analysis)
9. [Phase 6 â€” Model Training (Upcoming)](#9-phase-6--model-training-upcoming)
10. [Scoring Methodology](#10-scoring-methodology)
11. [Future Work & Conference Paper Direction](#11-future-work--conference-paper-direction)

---

## 1. Project Overview & Motivation

### What is this project?

This project performs **sentiment analysis on real-world smartphone reviews** scraped from Indian e-commerce platforms (Flipkart and Amazon India). The goal is to:

- Understand **what users actually say** about smartphones (beyond star ratings)
- Build a model that can **predict purchase intent / product satisfaction** from review text
- Produce results suitable for a **conference research paper** in the domain of NLP applied to consumer electronics

### Why this topic?

| Factor | Detail |
|--------|--------|
| Market Context | India is the world's 2nd largest smartphone market |
| Gap in Research | Most sentiment papers use English Twitter/IMDb data â€” Indian e-commerce product reviews are underexplored |
| Practical Value | A brand can know WHY their product is rated 3â˜… from review language, not just the number |
| Novel Contribution | Cross-device comparative sentiment scoring using augmented, curated Flipkart data |

### Devices Covered

| Device | Platform Scraped | Status |
|--------|-----------------|--------|
| iPhone 15 | Flipkart | âœ… 3,315 reviews collected |
| iPhone 16 | Flipkart | âœ… 719 reviews collected |
| iQOO Z10 | Flipkart | âœ… 57 reviews collected |
| iPhone 14 | Amazon India | âŒ Failed (bot detection) |
| iPhone 14 | Flipkart | âš ï¸ 9 reviews (JS-rendered, needs Selenium) |

---

## 2. System Architecture & SDLC Model

We follow a **modified Iterative SDLC model** â€” each phase produces a deliverable that feeds into the next, and failures cause a loop back to re-engineering.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ITERATIVE SDLC MODEL                         â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Phase 1 â”‚â”€â”€â”€â–¶â”‚  Phase 2 â”‚â”€â”€â”€â–¶â”‚  Phase 3 â”‚â”€â”€â”€â–¶â”‚  Phase 4 â”‚  â”‚
â”‚  â”‚  Data    â”‚    â”‚  EDA /   â”‚    â”‚  Data    â”‚    â”‚ Feature  â”‚  â”‚
â”‚  â”‚  Collect â”‚    â”‚  WordCld â”‚    â”‚  Augment â”‚    â”‚  Engg.   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚                                                â”‚        â”‚
â”‚       â”‚ (failure â†’ re-engineer scraper)               â”‚        â”‚
â”‚       â–¼                                               â–¼        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Scraper  â”‚                              â”‚  Phase 5         â”‚ â”‚
â”‚  â”‚ v1â†’v2â†’v3 â”‚                              â”‚  Sentiment       â”‚ â”‚
â”‚  â”‚ attempts â”‚                              â”‚  Analysis        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                       â”‚        â”‚
â”‚                                                       â–¼        â”‚
â”‚                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                                            â”‚  Phase 6         â”‚ â”‚
â”‚                                            â”‚  Model Training  â”‚ â”‚
â”‚                                            â”‚  + Prediction    â”‚ â”‚
â”‚                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### SDLC Phase Timeline

| Phase | Status | Output |
|-------|--------|--------|
| Requirements Analysis | âœ… Complete | Device list, platform selection |
| Data Collection | âœ… 3/4 devices | `.csv` review files |
| EDA & Visualization | âœ… Complete | Word clouds |
| Data Augmentation | âœ… Complete | Augmented CSVs (+24.9% data) |
| Feature Engineering | âœ… In Progress | TF-IDF, VADER, BERT features |
| Sentiment Analysis | âœ… Running | Sentiment scores per review |
| Model Training | ğŸ”„ Upcoming | Classifier model |
| Prediction & Evaluation | ğŸ”„ Future | Accuracy, F1, paper results |

---

## 3. Use Case Diagram

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚         RESEARCH SYSTEM             â”‚
                        â”‚                                     â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
  â”‚          â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â–¶â”‚ UC1: Scrape Reviews         â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - Select platform (FK/AMZ) â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - Paginate / Scroll        â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - Parse HTML cards         â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - Save to CSV              â”‚   â”‚
  â”‚          â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
  â”‚          â”‚          â”‚                                     â”‚
  â”‚Researcherâ”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
  â”‚  (You)   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â–¶â”‚ UC2: Generate Word Cloud    â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - Clean text               â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - Remove stopwords         â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - Render frequency map     â”‚   â”‚
  â”‚          â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
  â”‚          â”‚          â”‚                                     â”‚
  â”‚          â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â–¶â”‚ UC3: Augment Data           â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - Synonym replacement      â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - Word swap                â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - Preserve rating balance  â”‚   â”‚
  â”‚          â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
  â”‚          â”‚          â”‚                                     â”‚
  â”‚          â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â–¶â”‚ UC4: Sentiment Analysis     â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - VADER scoring            â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - Feature extraction       â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - Label assignment         â”‚   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                        â”‚                                     â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
  â”‚   ML     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â–¶â”‚ UC5: Train Classifier       â”‚   â”‚
  â”‚  Model   â”‚          â”‚  â”‚  - Vectorise reviews        â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - Train (SVM/BERT/RF)      â”‚   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚  - Evaluate (F1, Accuracy)  â”‚   â”‚
                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚                                     â”‚
  â”‚  End     â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
  â”‚  User /  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â–¶â”‚ UC6: Predict Satisfaction   â”‚   â”‚
  â”‚  Brand   â”‚          â”‚  â”‚  - Input: new review text   â”‚   â”‚
  â”‚          â”‚          â”‚  â”‚  - Output: sentiment label  â”‚   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚  - Output: confidence score â”‚   â”‚
                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Phase 1 â€” Data Collection (Scraping)

### 4.1 iPhone 15 & 16 â€” Flipkart (Page-based)

#### Why Flipkart?
Flipkart (India's largest e-commerce platform) renders **full HTML reviews server-side** for page numbers 1â€“N. Each page at `?page=N` returns a fresh HTML document with ~10 reviews embedded directly, making it ideal for `requests` + `BeautifulSoup` scraping.

#### Technology: `requests` + `BeautifulSoup`

```python
# Core pattern used for iPhone 15 and iPhone 16
url = f"{BASE_URL}&page={page_number}"
response = session.get(url, headers=headers, timeout=30)
soup = BeautifulSoup(response.text, 'html.parser')
```

**Why `requests`?**
- Simple synchronous HTTP â€” no browser overhead
- Session object maintains cookies across pages
- Works perfectly when Flipkart returns server-side rendered HTML

**Why `BeautifulSoup`?**
- HTML is not clean JSON â€” it's messy nested divs
- BeautifulSoup provides a Pythonic DOM traversal API
- `soup.find_all('div')` + text pattern matching was more robust than CSS class selectors (Flipkart changes class names frequently)

#### Review Parsing Strategy

The scrapers used a **pattern-based line parser** rather than fixed CSS classes. Each review div, when converted to text with `\n` separators, follows this pattern:

```
{RATING}        â† Line 0: single digit 1-5
{TITLE}         â† Line 1: review title
{REVIEW TEXT}   â† Lines 2+: review body
{CERTIFIED BUYER | DATE | CITY}  â† trailing metadata
```

Code approach:
```python
lines = [l.strip() for l in text.split('\n') if l.strip()]
if lines[0][0] in ['1','2','3','4','5']:
    rating = lines[0][0]
    # extract title and review from subsequent lines
```

#### Checkpoint & Resume System

Because scraping ~100+ pages takes hours, the scraper implemented:
- **Checkpoint every 5 pages** â†’ saves to CSV
- **Log file** (`simple_save.txt`) â†’ records `Page N: Found M reviews`
- **Resume logic** â†’ reads last logged page, resumes from `(last_page // 5) * 5 + 1`

This meant if the scraper crashed at page 73, it would resume from page 71 (nearest multiple of 5 + 1), preventing data loss.

#### Data Collected

| Device | Pages Scraped | Reviews | File |
|--------|-------------|---------|------|
| iPhone 15 | ~330+ | 3,315 | `iphone15_reviews.csv` |
| iPhone 16 | ~80+ | 719 | `iphone16_reviews.csv` |

#### Fields Extracted

```
rating     â†’ int (1â€“5)
title      â†’ str (review headline)
review_text â†’ str (full review body, cleaned)
date       â†’ str (e.g. "Jan 2024")
city       â†’ str (e.g. "Mumbai") or "N/A"
```

---

### 4.2 iQOO Z10 â€” Flipkart (Page-based)

Same scraper pattern as iPhone 15/16, adapted for iQOO Z10's Flipkart URL.

**Challenge:** iQOO Z10 had far fewer reviews (only 57), making the dataset highly imbalanced â€” this later drove the decision to apply aggressive data augmentation (+166.7%).

---

### 4.3 iPhone 14 â€” Amazon Scraper (Failed)

#### Attempt 1: Basic `requests`

Initial attempt used a simple `requests.get()` to Amazon's review page:

```
https://www.amazon.in/product-reviews/B0BDJS3MRM/
```

**Problem:** Reviews were overwritten on every run â€” the `_save()` function used `mode='w'` (write) instead of `mode='a'` (append).

**Fix:** Changed to append mode + checkpoint reading from log.

**New Problem discovered:** Amazon was returning **identical page 1 content** for every page number. Pages 2, 3, 4 ... all returned the same 7 reviews.

#### Attempt 2: TLS Fingerprinting Investigation

We ran `debug_page2.py` â€” a diagnostic script that fetched page 2 directly with plain `requests` and checked the review keys. Result:

```
Page 1: ['key_A', 'key_B', 'key_C', ... 7 reviews]
Page 2: ALL 7 reviews = DUP of page 1
```

Root cause: **Amazon detects Python's TLS fingerprint** (cipher suites, TLS version order) and serves a cached/bot response â€” always page 1 content regardless of `pageNumber` parameter.

#### Attempt 3: `curl_cffi` â€” Chrome TLS Impersonation

`curl_cffi` is a Python library that wraps `libcurl` and can **impersonate Chrome's exact TLS handshake** (cipher suite order, extensions, GREASE values):

```python
from curl_cffi import requests
session = requests.Session(impersonate='chrome131')
```

**What it does:** Makes the TLS handshake indistinguishable from a real Chrome 131 browser at the network level.

**Result:** Still returned duplicate pages. Amazon uses **additional server-side session locking** beyond TLS â€” likely IP-level rate limiting + cookie challenge.

#### Why Amazon Failed Permanently

| Detection Layer | Our Bypass Attempt | Result |
|----------------|-------------------|--------|
| User-Agent check | Rotated 5 real Chrome UAs | âŒ Still blocked |
| TLS fingerprint | `curl_cffi` chrome131 | âŒ Still blocked |
| Cookie/session | Extracted browser cookies | âŒ Session expired fast |
| JS challenge | Cannot execute without browser | âŒ Not attempted |

**Decision:** Abandoned Amazon for iPhone 14. Pivoted to Flipkart.

---

### 4.4 iPhone 14 â€” Flipkart Scraper (Failures)

#### Attempt 1: Page-based (`&page=N`) â€” Failed

Tried the same approach as iPhone 15/16:

```python
url = f"{BASE_URL}&page={page}"
```

**Problem:** Page 1 returned 200 OK with 9 reviews. Page 2 returned **HTTP 403 Forbidden**.

Investigation revealed Flipkart was checking the `Referer` header for subsequent pages. Added `Referer: {previous_url}` â€” still 403.

#### Why: reCAPTCHA Enterprise

The 403 response body was:

```html
<title>Flipkart reCAPTCHA</title>
<script src="https://www.google.com/recaptcha/enterprise.js?render=6Lc49B0p...">
```

Flipkart uses **reCAPTCHA Enterprise** which evaluates:
- TLS fingerprint
- Browser behaviour signals (mouse, timing)
- The `sidts` cookie â€” a **signed JavaScript-generated session token** that proves the client ran reCAPTCHA's JS successfully

When we injected browser cookies (including `sidts`), the `sidts` token was **already expired** (it's short-lived, generated by JS on each page load). An expired `sidts` = instant 403.

#### Attempt 2: `curl_cffi` + Cookie injection

```python
session = requests.Session(impersonate='chrome131')
session.cookies.set('sidts', '...', domain='.flipkart.com')
```

Result: Still 403 â€” the `sidts` token was stale the moment we copied it.

#### Attempt 3: No cookies, `curl_cffi` only

Tested without any cookies:
```
Status: 200 | Title: Apple iPhone 14 Reviews | CertifiedBuyer: False
```

200 OK but **no review content** â€” the page is an empty JavaScript shell. Reviews load dynamically via scroll events.

#### The Real Architecture: Infinite Scroll

iPhone 14's Flipkart review page is **React-rendered with infinite scroll**:
- Initial HTML only contains ~9 server-side-rendered reviews
- On scroll â†’ React app calls an internal API with `fetchId` + `pageNumber`
- That API (`/api/4/review/reviews?fetchId=...`) also returns 403 without a valid `sidts`

#### Current Status

- **9 reviews extracted** from the initial server-rendered HTML
- To get all reviews: need **Selenium** (real Chrome, executes JS, passes reCAPTCHA, scrolls)
- Selenium is installed (`selenium==4.39.0`, `webdriver-manager==4.0.2`)
- Implementation pending

#### What We Learned: Token-Based Access Pattern

Through these failures, we discovered Flipkart's **layered authentication model**:

```
Layer 1: TLS fingerprint    â†’ bypass with curl_cffi
Layer 2: User-Agent         â†’ bypass with real Chrome UA
Layer 3: Referer chain      â†’ bypass with session cookies
Layer 4: reCAPTCHA sidts    â†’ CANNOT bypass without real browser JS
Layer 5: API fetchId        â†’ extracted from page HTML (works if sidts valid)
```

This pattern of **JS-generated, short-lived session tokens** is the key reason HTTP-only scrapers fail on modern SPAs.

---

### 4.5 Technology Stack â€” Deep Technical Internals

---

#### A. `requests` Library â€” How It Works Internally

`requests` is a Python HTTP library built on top of `urllib3`. When you call `session.get(url)`, here is exactly what happens at every layer:

**Step 1 â€” URL Parsing**
```
https://www.flipkart.com/reviews?page=3
  â”‚
  â””â”€â–¶ scheme=https, host=flipkart.com, path=/reviews, query=page=3
```
The URL is decomposed by Python's `urllib.parse.urlsplit()` into components.

**Step 2 â€” DNS Resolution**
```
flipkart.com  â†’  DNS UDP query  â†’  203.x.x.x  (IP address)
```
Python calls the OS DNS resolver (or a cached entry from a previous request in the same session).

**Step 3 â€” TCP Three-Way Handshake**
```
Client â”€â”€SYNâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Server:443
Client â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€SYN-ACKâ”€â”€ Server
Client â”€â”€ACKâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Server
```
A TCP socket is opened on port 443. `urllib3` maintains a **connection pool** per host â€” if a previous request used the same host, the existing TCP socket is reused (keep-alive), saving ~100ms.

**Step 4 â€” TLS Handshake (HTTPS)**

This is the critical layer where bot detection happens:

```
Client Hello:
  â”œâ”€â”€ TLS version: 1.3
  â”œâ”€â”€ Cipher Suites: [0x1301, 0x1302, 0x1303, 0xc02b, ...]
  â”œâ”€â”€ Extensions: [server_name, supported_groups, ...]
  â””â”€â”€ Compression: none

Server Hello:
  â”œâ”€â”€ Chosen cipher: TLS_AES_128_GCM_SHA256
  â””â”€â”€ Certificate: *.flipkart.com
```

Python's default TLS is powered by **OpenSSL via the `ssl` module**. The specific order of cipher suites and extensions Python sends is **different from Chrome's**. This difference is the **JA3 fingerprint** â€” a 32-character MD5 hash computed as:

$$JA3 = MD5\bigl(TLSVersion, Ciphers, Extensions, EllipticCurves, EllipticCurveFormats\bigr)$$

For example:
- Python `requests` JA3: `a0e9f5d64349fb13191bc781f81f42e1`
- Chrome 131 JA3: `cd08e31494f9531f560d64c695473da9`

Sites like Amazon and Flipkart maintain a **JA3 blocklist** â€” if the fingerprint matches a known bot/scraper hash, the server returns a bot-response (page 1 HTML for every request, or 403).

**Step 5 â€” HTTP Request Construction**

`requests` builds a raw HTTP/1.1 message:
```
GET /reviews?page=3 HTTP/1.1
\n
Host: www.flipkart.com\r\n
User-Agent: python-requests/2.31.0\r\n
Accept-Encoding: gzip, deflate\r\n
Accept: */*\r\n
Connection: keep-alive\r\n
Cookie: _session=abc; ...\r\n
\r\n
```
This byte stream is written to the TLS-encrypted socket.

**Step 6 â€” Response Handling**

The server's response is read from the socket, decompressed (gzip/brotli), and decoded as UTF-8. `requests` wraps this in a `Response` object:
```python
response.status_code   # 200 / 403 / 429
response.text          # decoded HTML string
response.cookies       # Set-Cookie headers parsed into a CookieJar
```

**Session Cookie Persistence:** `requests.Session()` maintains a `http.cookiejar.CookieJar` internally. Every `Set-Cookie` header from responses is stored and replayed on subsequent requests to the same domain â€” mimicking browser cookie behaviour.

---

#### B. `BeautifulSoup` â€” HTML Parsing Internals

BeautifulSoup is a **tree-building library** â€” it does not fetch pages, only parses already-fetched HTML strings.

**Step 1 â€” Tokenisation (Lexer)**

With `html.parser` backend (Python's built-in), the raw HTML string is tokenised into a stream of tokens:
```
"<div class='fWi7J_'>5â˜… Great camera</div>"
    â”‚
    â–¼
Tokens:
  StartTag('div', [('class', 'fWi7J_')])
  Data('5â˜… Great camera')
  EndTag('div')
```
This tokeniser is a **state machine** â€” each character is fed into states (DATA, TAG_OPEN, ATTR_NAME, ATTR_VALUE, etc.) and transitions are defined by the HTML5 specification.

**Step 2 â€” Tree Construction**

Tokens are fed into a tree builder that constructs a nested Python object tree:
```
Tag('html')
  â””â”€ Tag('body')
       â””â”€ Tag('div', attrs={'class': ['fWi7J_']})
            â””â”€ NavigableString('5â˜… Great camera')
```
Each node is a Python object with `.parent`, `.children`, `.next_sibling` pointers â€” a classic **doubly-linked tree** structure stored entirely in RAM.

**Step 3 â€” Searching (find / find_all)**

When we call:
```python
cards = soup.find_all('div', class_='fWi7J_')
```
BeautifulSoup performs a **depth-first tree traversal**:
```
for every node in tree (DFS):
    if node.name == 'div'  AND  'fWi7J_' in node.attrs.get('class', []):
        yield node
```
Time complexity: **O(n)** where n = total nodes in the DOM tree. For a Flipkart review page (~5,000 DOM nodes), this completes in microseconds.

**Step 4 â€” Text Extraction**

`card.get_text(separator='\n', strip=True)` performs another DFS, collecting only `NavigableString` leaf nodes and joining them with `\n`. This is how we get the structured line-by-line review text for parsing.

**Why html.parser vs lxml?**

| Parser | Speed | Error Tolerance | Dependency |
|--------|-------|----------------|------------|
| `html.parser` | Medium | High (HTML5 spec) | Built-in Python |
| `lxml` | Fast (C library) | Very High | External C library |
| `html5lib` | Slow | Perfect (JS-equivalent) | External |

We used `html.parser` â€” no extra install needed, and Flipkart's HTML is clean enough not to require `lxml`'s superior error recovery.

---

#### C. `curl_cffi` â€” TLS Fingerprint Impersonation Internals

`curl_cffi` is a Python binding to **libcurl compiled with BoringSSL** (Google's fork of OpenSSL, the same TLS library Chrome uses). This is fundamentally different from Python's `requests` which uses OpenSSL.

**Why does TLS fingerprint matter?**

When your client connects via HTTPS, the **ClientHello** message includes:
```
Cipher Suites (in order):
  0x9a9a  â† GREASE value (Chrome randomises this)
  0x1301  â† TLS_AES_128_GCM_SHA256
  0x1302  â† TLS_AES_256_GCM_SHA384
  0x1303  â† TLS_CHACHA20_POLY1305_SHA256
  0xc02b  â† ECDHE-ECDSA-AES128-GCM-SHA256
  0xc02f  â† ECDHE-RSA-AES128-GCM-SHA256
  ...

Extensions (in order):
  0x0000  server_name (SNI)
  0x0017  extended_master_secret
  0xff01  renegotiation_info
  0x000a  supported_groups
  0x000b  ec_point_formats
  0x0023  session_ticket
  0x0010  ALPN (h2, http/1.1)
  0x0005  status_request
  ...
```

The **JA3 hash** is computed by the server from this message:

$$JA3_{string} = \text{TLSver},\text{Ciphers},\text{Extensions},\text{Groups},\text{Formats}$$

$$JA3_{hash} = MD5(JA3_{string})$$

Python `requests` with OpenSSL sends cipher suites in a **different order** and with **different extensions** than Chrome. curl_cffi with BoringSSL, combined with `impersonate='chrome131'`, **hardcodes Chrome 131's exact**:
- Cipher suite list and ordering
- Extension list and ordering
- GREASE (Generate Random Extensions And Sustain Extensibility) values â€” Chrome intentionally inserts random-looking values to prevent fingerprinting; curl_cffi replicates this
- TLS 1.3 record layer behaviour

**What happens internally when you call `Session(impersonate='chrome131')`:**

```python
session = requests.Session(impersonate='chrome131')
# Internally:
#  1. Loads curl_cffi's bundled BoringSSL
#  2. Sets CURLOPT_SSL_CIPHER_LIST to Chrome 131's exact cipher list
#  3. Sets CURLOPT_TLS13_CIPHERS for TLS 1.3 suites
#  4. Sets CURLOPT_HTTP2 = True (Chrome uses HTTP/2)
#  5. Sets CURLOPT_SSLVERSION = CURL_SSLVERSION_TLSv1_2 (minimum)
#  6. Injects GREASE values in extensions
#  7. Sets HTTP/2 SETTINGS frame to match Chrome's defaults
#  8. Sets H2 WINDOW_UPDATE to Chrome's exact value (15663105 bytes)
```

**HTTP/2 fingerprinting (beyond TLS):** Modern bot detection also analyses the HTTP/2 SETTINGS frame that Chrome sends immediately after the TLS handshake. Chrome's settings:
```
HTTP/2 SETTINGS:
  HEADER_TABLE_SIZE      = 65536
  ENABLE_PUSH            = 0
  MAX_CONCURRENT_STREAMS = (no limit)
  INITIAL_WINDOW_SIZE    = 6291456
  MAX_HEADER_LIST_SIZE   = 262144
```
curl_cffi replicates all of these exactly.

**Why it still failed on Amazon & Flipkart page 2:**
curl_cffi defeats **passive TLS/HTTP2 fingerprinting** but not **active behavioural challenges** like:
- reCAPTCHA Enterprise (requires JS execution to generate `sidts`)
- Amazon's `window.ue` object injection (JavaScript-evaluated)
- Cookie challenge flows that require visiting a challenge URL first

---

#### D. `Selenium` â€” How the Real Browser Scraper Works

Selenium is a **browser automation framework** that controls a real Chrome/Firefox instance via the **WebDriver protocol** (W3C standard, JSON over HTTP).

**Architecture:**
```
Your Python script
       â”‚  WebDriver Protocol (HTTP POST /session/{id}/element)
       â–¼
ChromeDriver (port 9515)
       â”‚  Chrome DevTools Protocol (CDP)
       â–¼
Chrome Browser Process
       â”‚  HTTPS
       â–¼
Flipkart Server
```

**What makes Selenium bypass all bot detection:**
1. Real Chrome process â€” TLS fingerprint is genuinely Chrome's (not emulated)
2. JavaScript engine (V8) executes reCAPTCHA's JS, generating a valid `sidts` token
3. Real mouse events, real timing â€” behavioural biometrics pass
4. Same cookies/storage as a normal browsing session

**Infinite Scroll Implementation:**
```python
driver.execute_script("window.scrollTo(0, document.body.scrollHeight)")
# This executes JavaScript inside the V8 engine of the Chrome tab
# Flipkart's React app listens for the 'scroll' event
# â†’ triggers XHR to /api/4/review/reviews?fetchId=...&page=N
# â†’ React appends new review cards to the DOM
# BeautifulSoup then re-parses the updated DOM
```

**CDP (Chrome DevTools Protocol) layer:** ChromeDriver communicates with Chrome via CDP â€” the same protocol used by Chrome DevTools. This means Selenium can:
- Read/write cookies, localStorage, sessionStorage
- Intercept network requests
- Execute JS in page context
- Take screenshots of the rendered page

---

#### E. Summary Comparison Table

| Technology | Transport | TLS Library | JA3 Match | Executes JS | Bot Bypass | Speed |
|-----------|-----------|------------|-----------|------------|-----------|-------|
| `requests` | urllib3/TCP | OpenSSL | âŒ Python JA3 | âŒ | Basic | Fast |
| `curl_cffi` | libcurl/TCP | BoringSSL | âœ… Chrome JA3 | âŒ | TLS fingerprint | Fast |
| `Selenium` | Real Chrome | BoringSSL | âœ… Genuine | âœ… V8 engine | All passive+active | Slow |
| `httpx` | async TCP | OpenSSL | âŒ | âŒ | Basic | Fast |

---

---

## 5. Phase 2 â€” Word Cloud Generation

### Purpose

Before any ML, we performed **Exploratory Data Analysis (EDA)** via word clouds to visually understand what vocabulary dominates each device's reviews.

### Word Clouds Generated

| Device | File | Key Dominant Terms |
|--------|------|--------------------|
| iPhone 15 | `iphone_15_wordcloud.png` | camera, battery, performance, display |
| iPhone 16 | `iphone_16_wordcloud.png` / `iphone16_wordcloud.png` | camera, chip, price, upgrade |
| iQOO Z10 | `iqoo_z10_wordcloud.png` | battery, gaming, display, value |

### Generation Process

```python
from wordcloud import WordCloud
import matplotlib.pyplot as plt

text = ' '.join(df['review_text'].dropna())
wc = WordCloud(
    width=800, height=400,
    background_color='white',
    stopwords=STOPWORDS,
    max_words=200
).generate(text)
plt.imshow(wc, interpolation='bilinear')
plt.axis('off')
plt.savefig(f'{device}_wordcloud.png', dpi=150)
```

### Key Insights from Word Clouds

**iPhone 15:** "camera" appears largest â†’ users primarily bought/reviewed for camera quality. Strong positive vocabulary ("amazing", "perfect", "best").

**iPhone 16:** "chip", "performance", "A18" â€” buyers focused on chipset upgrade. Negative terms ("price", "expensive") also visible â†’ price-to-value concern.

**iQOO Z10:** "battery", "gaming" dominate â€” budget Android segment buyers prioritise endurance and gaming performance. More technical vocabulary than iPhone reviews.

---

## 6. Phase 3 â€” Data Augmentation

### Why Augmentation Was Needed

After collecting data, the dataset was **highly imbalanced**:

```
iPhone 15:   3,315 reviews  â† reasonable
iPhone 16:     719 reviews  â† sparse
iQOO Z10:       57 reviews  â† critically small
```

57 reviews for iQOO Z10 is insufficient for any ML model â€” it would overfit immediately. We needed more data without re-scraping.

**Theoretical justification:** For a classifier trained on $n$ samples with $k$ classes, the **Vapnik-Chervonenkis bound** states that the expected generalisation error is bounded by:

$$\epsilon \leq \sqrt{\frac{d \cdot \ln(2n/d) + \ln(1/\delta)}{n}}$$

Where $d$ = VC dimension (complexity of hypothesis space) and $\delta$ = confidence. With $n=57$ and a TF-IDF + SVM model where $d \approx 5000$, the error bound is ~0.99 (useless). After augmentation to $n=152$, it drops to ~0.63 â€” still not great, which is why we also apply VADER-based features to reduce effective $d$.

---

### Technique 1 â€” Synonym Replacement

#### What it is

Replace a randomly chosen subset of content words (nouns, adjectives, verbs) with synonyms from a curated domain lexicon, producing a new review with the **same semantic meaning but different surface form**.

#### Mathematical Model

For a review $R = [w_1, w_2, \ldots, w_n]$, let $S \subseteq \{1 \ldots n\}$ be the set of indices of synonym-eligible words (not stopwords, not sentiment words). For each index $i \in S$, we apply an **independent Bernoulli trial**:

$$X_i \sim \text{Bernoulli}(p),\quad p = 0.30$$

If $X_i = 1$, word $w_i$ is replaced by a uniformly-sampled synonym:

$$w_i' = \text{Uniform}\bigl(\text{synonyms}(w_i)\bigr)$$

The expected number of replacements per review of length $n$ with $|S|$ eligible words is:

$$\mathbb{E}[\text{replacements}] = p \cdot |S| = 0.30 \times |S|$$

For a 50-word review with 30 eligible content words: $\mathbb{E} = 0.30 \times 30 = 9$ words replaced.

#### Synonym Lexicon (Domain-Specific)

```python
SYNONYMS = {
    # Positive adjectives
    'good':        ['great', 'excellent', 'nice', 'wonderful', 'superb'],
    'amazing':     ['fantastic', 'outstanding', 'impressive', 'brilliant'],
    'best':        ['top', 'finest', 'premier', 'superior'],
    'fast':        ['quick', 'rapid', 'swift', 'snappy', 'speedy'],
    'smooth':      ['fluid', 'seamless', 'responsive', 'effortless'],

    # Product nouns
    'camera':      ['photography', 'picture quality', 'imaging', 'lens'],
    'phone':       ['device', 'handset', 'mobile', 'smartphone', 'unit'],
    'battery':     ['power', 'charge', 'battery life', 'backup', 'endurance'],
    'display':     ['screen', 'panel', 'monitor', 'visual'],
    'performance': ['speed', 'capability', 'efficiency', 'computing power'],

    # Negative adjectives
    'bad':         ['poor', 'terrible', 'awful', 'disappointing'],
    'slow':        ['sluggish', 'laggy', 'unresponsive', 'delayed'],
    'expensive':   ['pricey', 'overpriced', 'costly', 'steep'],
}
```

**Why domain-specific synonyms and not WordNet?**

WordNet (the standard English synonym database) maps "camera" â†’ "television camera", "photographer" â€” technically correct but sounds unnatural in product reviews. Domain-specific synonyms like "photography" or "picture quality" are **contextually appropriate** to the e-commerce review domain and won't confuse the model.

**Why exclude sentiment words from replacement?**

The review `"battery is bad"` must NOT become `"power is good"`. Replacing sentiment words (good/bad/terrible/excellent) would flip the polarity, introducing **label noise** â€” a 1-star review would read like a 5-star review. So only **content words** (product features, nouns) are eligible for replacement, never polarity words.

#### Example Transformation

```
Original: "The camera quality is good and battery backup is fast"
          â†“ X_i trials: camera(1), good(0), battery(1), fast(1)
Augmented: "The photography quality is good and power backup is quick"
```

---

### Technique 2 â€” Random Word Swap

#### What it is

Random word swap selects two positions $i$ and $j$ in the word list uniformly at random and swaps them. Repeated $k$ times per review.

#### Mathematical Model

Given $R = [w_1, w_2, \ldots, w_n]$, we draw a pair of indices:

$$(i, j) \sim \text{Uniform}\bigl(\{(a,b) : 1 \leq a < b \leq n\}\bigr)$$

And swap: $w_i \leftrightarrow w_j$. We perform $k = \lfloor n/10 \rfloor$ swaps (proportional to review length), minimum 1.

For a 50-word review: $k = 5$ swaps. The number of possible unique orderings produced is:

$$\text{distinct permutations} \leq \frac{n!}{\prod_i f_i!}$$

Where $f_i$ is the frequency of each unique word (accounting for repeated words reducing distinct permutations).

**Why word swap preserves sentiment:** Swapping word positions does not change which words are present â€” only their order. Since sentiment is primarily a **bag-of-words** signal (the polarity of individual words), swapping preserves the overall sentiment score. A classifier trained with TF-IDF (which also ignores word order) sees the swapped review as nearly identical â€” but at the surface text level it appears different, preventing duplicates.

#### Example Transformation

```
Original: "great camera performance and long battery life"
          indices:  1      2        3         4    5       6
          swap(2,5): camera â†” battery
Swapped:  "great battery performance and long camera life"
```

The meaning is slightly garbled but semantically recoverable â€” a model learning from both versions becomes more robust to word-order variation in real reviews.

---

### Technique 3 â€” Quality Control Pipeline

After generating augmented reviews, each candidate goes through a 3-stage filter:

**Stage 1 â€” Exact Duplicate Check**
```python
all_reviews = set(original_df['review_text'].str.lower().str.strip())
if augmented_review.lower().strip() in all_reviews:
    discard()  # Too similar to an existing review
```

**Stage 2 â€” Similarity Threshold (Jaccard)**

For each augmented review $R'$ and its source review $R$, compute **Jaccard similarity** on word sets:

$$J(R, R') = \frac{|\text{words}(R) \cap \text{words}(R')|}{|\text{words}(R) \cup \text{words}(R')|}$$

Accept if $0.40 \leq J(R, R') \leq 0.95$:
- Below 0.40: too different â€” meaning may have changed
- Above 0.95: too similar â€” barely any new surface variation

**Stage 3 â€” Rating Inheritance**

Augmented review inherits the exact rating of its source:
```python
aug_df['rating'] = source_df['rating']  # Direct copy, no modification
```

This ensures the **label distribution of augmented data equals the original** â€” no class imbalance is introduced.

---

### Technique 4 â€” EDA Text Normalisation (Pre-Augmentation)

Before augmentation, all review text was normalised:

```python
import re

def clean(text):
    text = text.lower()                          # Lowercase
    text = re.sub(r'[^a-z0-9\s]', '', text)      # Remove punctuation
    text = re.sub(r'\s+', ' ', text).strip()     # Collapse whitespace
    text = re.sub(r'(.)\1{2,}', r'\1\1', text)  # "greaaaat" â†’ "greaat"
    return text
```

The repeated-character normalisation (`r'(.)\1{2,}'`) uses a **backreference regex** â€” `\1` refers back to the captured group `.` (any character). So any character repeated 3+ times is reduced to exactly 2 repetitions: "greaaaat" â†’ "greaat", "!!!" â†’ "!!". This prevents augmentation from producing wildly elongated tokens.

---

### Results

| Device | Original | Augmented | Growth |
|--------|----------|-----------|--------|
| iPhone 15 | 3,315 | 4,061 | +22.5% |
| iPhone 16 | 719 | 895 | +24.5% |
| iQOO Z10 | 57 | 152 | **+166.7%** |
| **Total** | **4,091** | **5,108** | **+24.9%** |

### Rating Distribution Preservation (iPhone 15 example)

| Rating | Original | Augmented | % Change |
|--------|----------|-----------|----------|
| â­ | 143 (4.3%) | 181 (4.5%) | +26.6% |
| â­â­ | 49 (1.5%) | 59 (1.5%) | +20.4% |
| â­â­â­ | 105 (3.2%) | 125 (3.1%) | +19.0% |
| â­â­â­â­ | 414 (12.5%) | 516 (12.7%) | +24.6% |
| â­â­â­â­â­ | 2,604 (78.6%) | 3,180 (78.3%) | +22.1% |

The distribution is **statistically preserved** â€” augmentation did not introduce class imbalance.

### Why This Approach vs. Deep Learning Augmentation?

| Method | How It Works | Our Choice? | Reason |
|--------|-------------|------------|--------|
| **Synonym Replacement** | Lexicon lookup, Bernoulli trial | âœ… Yes | Fast, deterministic, domain-controlled |
| **Word Swap** | Random index transposition | âœ… Yes | Zero external dependency, preserves vocabulary |
| **Back-Translation** | Translate ENâ†’HIâ†’EN via API | âŒ No | Requires Google API, slow, costly |
| **GPT Paraphrase** | Prompt LLM to rewrite | âŒ No | Requires API, expensive at 4000+ reviews |
| **EDA (nlpaug)** | Full NLP augmentation suite | âŒ Not used | Overkill for this domain; our custom synonyms better |
| **SMOTE** | KNN interpolation in feature space | âŒ N/A | Works on numerical features, not raw text |

Our approach is a **lightweight, reproducible, domain-adapted EDA (Easy Data Augmentation)** implementation â€” well-suited for a research paper where the augmentation method itself must be explainable and verifiable.

---

## 7. Phase 4 â€” Feature Engineering & Selection

### Iteration 1 â€” Basic Text Features

Initial features:
- `review_length` (character count)
- `word_count`
- `rating` (raw 1â€“5)

**Problem:** These features were too shallow. A 200-character 1-star review and a 200-character 5-star review look identical numerically.

### Iteration 2 â€” TF-IDF Vectorisation

Added **TF-IDF (Term Frequencyâ€“Inverse Document Frequency)**:

```python
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))
X = vectorizer.fit_transform(df['review_text'])
```

- Unigrams + bigrams (`ngram_range=(1,2)`) capture phrases like "battery life", "camera quality"
- `max_features=5000` prevents dimensionality explosion
- IDF down-weights common words ("phone", "product") that appear in all reviews

**Improvement:** Model could now distinguish vocabulary patterns across ratings.

**Problem:** TF-IDF is **bag-of-words** â€” loses word order and context. "Not good" and "good" have similar TF-IDF signatures.

### Iteration 3 â€” VADER Sentiment Scores as Features

Added **VADER (Valence Aware Dictionary and sEntiment Reasoner)** scores as explicit features:

```python
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
sia = SentimentIntensityAnalyzer()
df['vader_pos']  = df['review_text'].apply(lambda x: sia.polarity_scores(x)['pos'])
df['vader_neg']  = df['review_text'].apply(lambda x: sia.polarity_scores(x)['neg'])
df['vader_compound'] = df['review_text'].apply(lambda x: sia.polarity_scores(x)['compound'])
```

**Why VADER?**
- Specifically designed for social media / short reviews
- Handles capitalisation ("AMAZING"), punctuation ("great!!!"), slang
- Compound score ranges -1.0 (most negative) to +1.0 (most positive)
- Works without training data â€” pure lexicon-based

**Improvement (iPhone 16):** Correlation between `vader_compound` and actual rating = 0.73. Strong signal.

**Problem (iQOO Z10):** With only 57 original samples, VADER alone caused overfitting. Fixed by augmentation (+166.7%).

### Current Feature Set (Per Review)

```
Numerical:
  - rating (1â€“5)
  - word_count
  - vader_pos, vader_neg, vader_neu, vader_compound
  - has_keywords: camera, battery, price, display, performance (binary flags)

Text (vectorised):
  - TF-IDF(review_text, max=5000, ngram=(1,2))
  - TF-IDF(title, max=500)
```

---

## 8. Phase 5 â€” Sentiment Analysis

### Notebooks

| Notebook | Device | Status |
|----------|--------|--------|
| `iphone16 centimental analysis.ipynb` | iPhone 16 | âœ… Complete |
| `iqoo_z10 analysis.ipynb` | iQOO Z10 | âœ… Complete |
| iPhone 15 analysis | iPhone 15 | ğŸ”„ In progress |
| iPhone 14 analysis | iPhone 14 | â³ Pending (data incomplete) |

### Labelling Strategy

Since our data has **star ratings (1â€“5)** but we need sentiment labels, we map:

```python
def label(rating):
    if rating >= 4:  return 'Positive'
    if rating == 3:  return 'Neutral'
    if rating <= 2:  return 'Negative'
```

This gives us a **3-class classification problem** consistent with standard sentiment analysis literature.

### Scoring Methodology

#### VADER Compound Score Interpretation

```
compound >= 0.05  â†’ Positive sentiment
compound <= -0.05 â†’ Negative sentiment
-0.05 < compound < 0.05 â†’ Neutral
```

#### Cross-validation with Rating

We compute a **Sentiment Consistency Score (SCS)**:

```
SCS = % reviews where VADER label matches rating-derived label
```

Results:
- iPhone 16: SCS = 78.3% (strong alignment)
- iQOO Z10: SCS = 71.2% (acceptable; small dataset)

Discrepancies (e.g. 5â˜… review with negative VADER) are flagged as **ironic/sarcastic reviews** or cases where users gave 5â˜… despite mentioning negatives ("Battery is bad but overall 5 stars anyway").

### Output Files

- `iphone16_final_sentiment_analysis.xls` â€” full review-level sentiment scores
- `iqoo_z10_final_sentiment_analysis.xls` â€” same for iQOO Z10

---

## 9. Phase 6 â€” Model Training (Upcoming)

### Planned Pipeline

```python
from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC
from sklearn.feature_extraction.text import TfidfVectorizer

pipeline = Pipeline([
    ('tfidf',   TfidfVectorizer(max_features=5000, ngram_range=(1,2))),
    ('clf',     LinearSVC(C=1.0, max_iter=2000))
])
pipeline.fit(X_train, y_train)
```

### Models to Evaluate

| Model | Rationale |
|-------|-----------|
| **LinearSVC** | Fast, strong baseline for text classification |
| **Multinomial Naive Bayes** | Probabilistic, good with TF-IDF features |
| **Random Forest** | Can capture feature interactions (VADER + TF-IDF) |
| **BERT (bert-base-uncased)** | State-of-art contextual embeddings â€” handles negation, context |

### Evaluation Metrics

```
Primary:   Weighted F1-score (handles class imbalance)
Secondary: Accuracy, Precision, Recall (per class)
Cross-val: Stratified 5-fold
```

### Why Stratified K-Fold?

Our dataset is imbalanced (~78% are 5â˜… reviews). Random splits could produce test folds with no negative samples. Stratified K-Fold ensures each fold has proportional class representation.

---

## 10. Scoring Methodology

### Device-Level Sentiment Score

Beyond per-review classification, we compute an aggregate **Device Sentiment Score (DSS)**:

$$DSS = \frac{\sum_{i=1}^{N} (w_i \times compound_i)}{N}$$

Where:
- $w_i$ = upvote weight of review $i$ (if available, else 1.0)
- $compound_i$ = VADER compound score of review $i$
- $N$ = total number of reviews

### Feature-Level Breakdown Score

We identify key product features (camera, battery, price, display, performance) and compute sentiment scores **per feature**:

```python
features = {
    'camera':      r'camera|photo|picture|lens|zoom',
    'battery':     r'battery|charge|charging|backup',
    'performance': r'fast|speed|lag|smooth|processor|chip',
    'display':     r'screen|display|brightness|amoled',
    'price':       r'price|value|worth|expensive|cheap',
}

for feature, pattern in features.items():
    mask = df['review_text'].str.contains(pattern, case=False)
    df.loc[mask, f'{feature}_score'] = df.loc[mask, 'vader_compound']
```

This produces a **radar chart** per device showing relative strengths and weaknesses.

---

## 11. Future Work & Conference Paper Direction

### Research Question

> *"Can a multi-feature NLP model trained on augmented Indian e-commerce smartphone reviews produce reliable sentiment predictions, and do these predictions correlate with market performance indicators?"*

### Planned Contributions

1. **Novel Dataset:** Curated, cleaned, augmented Flipkart smartphone reviews (Indian market) â€” not available in existing literature
2. **Comparative Analysis:** Cross-device sentiment comparison (premium iPhone 15/16 vs budget iQOO Z10) â€” tests if model generalises across price segments
3. **Hybrid Feature Model:** Combined TF-IDF + VADER + rating features outperforming single-method baselines
4. **Augmentation Methodology:** Documented synonym-replacement augmentation for e-commerce text (reproducible)

### Expected Results (Hypothesis)

| Model | Expected F1 |
|-------|------------|
| Baseline (rating only) | 0.72 |
| TF-IDF + LinearSVC | 0.81 |
| TF-IDF + VADER + SVC | 0.85 |
| Fine-tuned BERT | 0.89+ |

### Conference Targets

- **ICACCI** (International Conference on Advances in Computing, Communications and Informatics)
- **INDICON** (IEEE India Conference)
- **ICCIDS** (International Conference on Computational Intelligence in Data Science)

### Remaining Work Before Submission

| Task | Priority | Estimated Effort |
|------|----------|-----------------|
| iPhone 14 Selenium scraper | High | 2 days |
| iPhone 15 sentiment notebook | High | 1 day |
| Model training script | High | 3 days |
| Comparative evaluation across devices | High | 2 days |
| Paper writing | High | 1 week |
| BERT fine-tuning (optional) | Medium | 3 days |
| Cross-platform validation (Amazon vs Flipkart) | Low | Future work |

---

## Appendix: File Structure

```
minor 2/
â”œâ”€â”€ data_scrapping/
â”‚   â”œâ”€â”€ iphone14/
â”‚   â”‚   â”œâ”€â”€ simple_scraper.py       â† curl_cffi, single fetch, 9 reviews
â”‚   â”‚   â”œâ”€â”€ amazon_scraper.py       â† ABANDONED (TLS bot detection)
â”‚   â”‚   â”œâ”€â”€ iphone14_reviews.csv    â† 9 reviews (partial)
â”‚   â”‚   â””â”€â”€ debug_*.py              â† diagnostic scripts
â”‚   â”œâ”€â”€ iphone15/
â”‚   â”‚   â”œâ”€â”€ simple_scraper.py       â† requests + BS4, page-based âœ…
â”‚   â”‚   â””â”€â”€ iphone15_reviews.csv    â† 3,315 reviews
â”‚   â”œâ”€â”€ iphone16/
â”‚   â”‚   â”œâ”€â”€ simple_scraper.py       â† requests + BS4, page-based âœ…
â”‚   â”‚   â””â”€â”€ iphone16_reviews.csv    â† 719 reviews
â”‚   â””â”€â”€ iqoo_zx10/
â”‚       â”œâ”€â”€ simple_scraper.py       â† requests + BS4, page-based âœ…
â”‚       â””â”€â”€ iqoo_z10_reviews.csv    â† 57 reviews
â”œâ”€â”€ augmented_data/
â”‚   â”œâ”€â”€ iphone15_augmented.csv      â† 4,061 reviews
â”‚   â”œâ”€â”€ iphone16_augmented.csv      â† 895 reviews
â”‚   â”œâ”€â”€ iqoo_z10_augmented.csv      â† 152 reviews
â”‚   â””â”€â”€ AUGMENTATION_SUMMARY.md
â”œâ”€â”€ sentimental_analysis/
â”‚   â”œâ”€â”€ iphone16 centimental analysis.ipynb
â”‚   â”œâ”€â”€ iphone16_final_sentiment_analysis.xls
â”‚   â”œâ”€â”€ iqoo_z10 analysis.ipynb
â”‚   â””â”€â”€ iqoo_z10_final_sentiment_analysis.xls
â”œâ”€â”€ wordclouds/
â”‚   â”œâ”€â”€ iphone_15_wordcloud.png
â”‚   â”œâ”€â”€ iphone_16_wordcloud.png
â”‚   â””â”€â”€ iqoo_z10_wordcloud.png
â”œâ”€â”€ model_training/                 â† EMPTY â€” upcoming phase
â”œâ”€â”€ generate_all_wordclouds.py
â”œâ”€â”€ quick_augment.py
â””â”€â”€ PROJECT_REPORT.md               â† THIS FILE
```

---

*Document maintained by the research team. Last updated: February 2026.*
